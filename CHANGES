* добавлен этот файл;
* добавлен класс соединений Wire, добавлен юнит-тест для Wire;

* введен дополнительный класс Succession, общий для Model и Successor. Теперь можно
  составлять композиции из Model;
* добавлен тест для композиции Model;
* небольшие изменения тестов - исправлен охват параметров шаблона;

* добавлена Doxygen - документация ко всем классам;

* удалена неиспользуемая переменная time_ и класса ANN (за время отвечает Учитель с переменной sampleCount_);
* дополнена документация;
* индексные сеттеры и геттеры класса ANN теперь final, их реализации вынесены в базовый класс;
* добавлен класс Reshape, меняющий форму тензора на другую, с таким же объемом;
* исправлен метод setTutor в дочерних классах - он теперь не выбрасывает исключения, и кое-где удален вообще;
* в Model добавлен вариативный метод setTutor позволяющий установить Учителя сразу для всех подсетей;

* добавлен класс SoftMax и юнит-тест для него;
* исправлен конструктор в ANN;

* удалены методы ANN::setMode()/getMode() как нефункциональные;
* еще несколько методов ANN стали чисто-виртуальными. Это немного раздувает код дочерних классов, за то улучашает читабельность;
* методы Learnable::batchBegin()/batchEnd() теперь final;
* добавлена разметка Doxygen в ANN.hpp;

* добавлена поддержка регуляризации;
* регуляризация реализована в SimpleTutor;
* удален метод DataHolder::update() и его тесты;
* добавлены комментарии Doxygen;

* добавлен класс Generator - входного слоя сети, генерирующей шум для GAN;

* добавлена библиотека Tensor2JPEG;
* добавлена библиотека для работы с MNIST;
* добавлен тест для работы с MNIST и toJPEG;

* Arctan, тест для Arctan;
* простой классификатор MNIST;
* добавлен слой Gain, тест для Gain;
* в классы сети добавлен диагностический метод dump();
* в SoftMax и ANN добавленны ассерты;
* добавлен прототип классификатора для MNIST, вроде даже работает;
* добавлена поддержка OpenMP;

* ReLUx и тест;
* ELU и тест;
* метод Model::addLayer() теперь реализован через вариативный шаблон и может принимать дополнительные аргументы;
* SELU и тест;
* инициализация Layer;

* добавлен отладочный слой Assertion для отслеживания ошибок при передаче данных между слоями;
* добавлена библиотека для тестирования нейросетевых моделей;
* класс Arctan переведен на библиотеку юнит-тестирования моделей;

* упорядочен механизм работы с ГСЧ;
* классификатор дает на MNIST ошибку порядка 3.7%;

* -Wall
* -Wextra

* ReLU - переделан тест;
* добавлен пример генерации картинок для TestModel -- fuzzy2jpeg;
TODO: подумать о переделке DataHolder/Tensor/tensormath  в Абстрактную Фабрику или типа того, дабы сделать CUDA;

* Tensor объединен с tensormath и вынесен из DataHolder;
* в корневой main.cpp добавлено измерение времени;

* добавлен Timer.hpp для измерения времени работы;
* расширено тестирование DataHolder;

* добавлено измерение таймингов прямого и обратного распространения ошибки и обучения в класс тестирования;
* обновлены комментарии для Doxygen;

* оптимизация Tensor::val();
* добавлен код для цветного вывода текста в консоль -- Console.hpp
* статистика по тестированию теперь цветная;
* добавлен тест на оператор поворота в трехмерном пространстве TestRot3;
* тест для Layer модифицирован для оператора поворота;

* добавлен слой Dropout;
* добавлен поддержка Dropout в ModelTest;
* добавлено распределение Бернулли в Tensor;
* добавлено поэлементное перемножение тензоров Tensor::prod();
* добавлена рассылка событий по сети, для управления отдельными слоями и компонентами;

* добавлен метод Tensor::prodapp();
* обновлен код Gain переходом на Tensor::prod() и prodapp();

* добавлен метод Tensor::fill(val);
* добавлен юнит-тест для Dropout;
* из Timer вынесен код онлайн-оценки статистических параметров случайной величины в OnlineStatistics;
* добавлен дропаут в examples/fuzzy2jpeg;

* настройки exaples/MNIST.classifier и правки MNIST:
    - работа над ошибками;
    - перемешивание выборки;
    - инкапсуляция семплов;

* добавлен метод оптимизции Нестерова;
* добавлен отдельный тест для методов оптимизации;
* добавлен метод AbstractTutor::clone() для замены учителя налету;

* Изменен DataHolder::clone() для реализации паттерна Прототип; 
* Соответсвующие изменеия в Learnable;

* Добавлен интерфейс IDataHolder;

* Исправления в Makefile;

* Добавлен интерфейс ITensor;

* Перевод фронтенда на ITensor и IDataHolder;
* Добавлен оператор osteram<<Timer;
* изменено отображение времени в TestModel::elapsed();

* Добавлена абстрактная фабрика IBackendFactory;
* Добавлена фабрика бэкенда для работы с OpenMP BackendOpenMP;
* Масштабный рефакторинг фронтенда и тестов, дабы все работало;
* ... и все работает! Теперь можно легко добавить бэкенды для тензорной математики, например для CUDA.
* В ANN добавлен виртуальный метод build() для установки нужного бэкенда;
* В ANN добавлен метод shape() дабы форма каждого компонента сети была известна до вызова метода build();

* clone() перенесен из DataHolder и IDataHolder, добавлен метод makeEmptyObject();
* build() перенесен в IDataHolder, добавлен виртуальный метод allocate();
* в IDataHolder добавлен одномерный тензор с именем "*" для сквозного именования всего хранилища;
* все вычисления полностью вынесены в ITensor, в том числе и методы оптимизации:
    - optGrad() - градиентный метод с постоянным шагом;
    - optNesterov() - инерционный градиентный метод Нестерова;
* шаблон DataHolder теперь зависит от тензора;
* работа напрямую с DataHolder убрана из всех тестов, взамен используется фабрика. Теперь можно тестировать разные бэкенды.
* обновлены тесты;

* Tensor -> TensorOMP;

* добавлен AdamTutor и тесты к нему;
